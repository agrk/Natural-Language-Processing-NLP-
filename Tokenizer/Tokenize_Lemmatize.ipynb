{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........TOKENIZATION..........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"..........TOKENIZATION..........\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text= \"\"\"Artificial Intelligence is a complex\n",
    "              field with many components and methodologies \n",
    "              used to achieve the final result — an \n",
    "              intelligent machine. AI was developed\n",
    "              by studying the way the human brain thinks,\n",
    "              learns and decides, \n",
    "              then applying those biological\n",
    "              mechanisms to computers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'Intelligence', 'is', 'a', 'complex', 'field', 'with', 'many', 'components', 'and', 'methodologies', 'used', 'to', 'achieve', 'the', 'final', 'result', '—', 'an', 'intelligent', 'machine', '.', 'AI', 'was', 'developed', 'by', 'studying', 'the', 'way', 'the', 'human', 'brain', 'thinks', ',', 'learns', 'and', 'decides', ',', 'then', 'applying', 'those', 'biological', 'mechanisms', 'to', 'computers', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(Text))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MWETokenizer([('Artificial', 'Intelligence'), ('many', 'components')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_mwe(('human', 'brain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Multi Word Tokenization..........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\".........Multi Word Tokenization..........\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_token=tokenizer.tokenize(Text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial_Intelligence', 'is', 'a', 'complex', 'field', 'with', 'many_components', 'and', 'methodologies', 'used', 'to', 'achieve', 'the', 'final', 'result', '—', 'an', 'intelligent', 'machine.', 'AI', 'was', 'developed', 'by', 'studying', 'the', 'way', 'the', 'human_brain', 'thinks,', 'learns', 'and', 'decides,', 'then', 'applying', 'those', 'biological', 'mechanisms', 'to', 'computers.']\n"
     ]
    }
   ],
   "source": [
    "print(mwe_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "........LEMMATIZATION.............................................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n........LEMMATIZATION.............................................................................\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_list = word_tokenize(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'Intelligence', 'is', 'a', 'complex', 'field', 'with', 'many', 'components', 'and', 'methodologies', 'used', 'to', 'achieve', 'the', 'final', 'result', '—', 'an', 'intelligent', 'machine', '.', 'AI', 'was', 'developed', 'by', 'studying', 'the', 'way', 'the', 'human', 'brain', 'thinks', ',', 'learns', 'and', 'decides', ',', 'then', 'applying', 'those', 'biological', 'mechanisms', 'to', 'computers', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer_list)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemma_out = ' '.join([lemmatizer.lemmatize(w,'v') for w in lemmatizer_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence be a complex field with many components and methodologies use to achieve the final result — an intelligent machine . AI be develop by study the way the human brain think , learn and decide , then apply those biological mechanisms to computers .\n"
     ]
    }
   ],
   "source": [
    "print(Lemma_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
